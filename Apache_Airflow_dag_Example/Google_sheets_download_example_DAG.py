### --- –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫ ---

# === –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ ===
import requests

# === –†–∞–±–æ—Ç–∞ —Å –≤—Ä–µ–º–µ–Ω–µ–º –∏ –¥–∞—Ç–∞–º–∏ ===
import pendulum

# === Airflow ===
from airflow import DAG
from airflow.decorators import dag, task
from airflow.hooks.base_hook import BaseHook

### --- --- ###

# –í–ª–∞–¥–µ–ª–µ—Ü
default_args = {
    'owner': 'username_example',
    'retries': 2,
    'retry_delay': pendulum.duration(minutes=5),
}


# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—É—Å–∫–∞ DAG'–∞
@dag(
    schedule='0 8 * * 3',  # –∫–∞–∂–¥—É—é —Å—Ä–µ–¥—É –≤ 8 —É—Ç—Ä–∞
    start_date=pendulum.datetime(2025, 1, 1, tz="Europe/Moscow"),
    catchup=False,
    tags=["Tag_Example"], # –ü–æ –¥–∞–Ω–Ω–æ–º—É —Ç–µ–≥—É –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –≤ —Å–ø–∏—Å–∫–µ –¥–∞–≥–æ–≤
    default_args=default_args
)
def m_pid_sub_base_list_updater():
    import numpy as np
    import pandas as pd
    import clickhouse_connect

#######################################################################################
################  Step 1 ####################################################
######################################################################################    
    @task #### –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Å –≤–∞–ª
    def df_from_val(query, base="val"):     
        conn_val = BaseHook.get_connection('username_val_conn') # # –ü—Ä–∏–º–µ—Ä —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        client = clickhouse_connect.get_client(
            host=conn_val.host,
            database=base,
            username=conn_val.login,
            password=conn_val.password
        )
        pd.set_option('display.float_format', lambda x: '%.10f' % x)        
        df = client.query_df(query)
        
        return df

    @task ### –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Å –º_–ø–∞—Ä—Ç–Ω–µ—Ä—Å
    def df_from_m_partner(query, base="m_partner"):     
        conn_val = BaseHook.get_connection('username_m_partner') # # –ü—Ä–∏–º–µ—Ä —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        client = clickhouse_connect.get_client(
            host=conn_val.host,
            database=base,
            username=conn_val.login,
            password=conn_val.password
        )
        pd.set_option('display.float_format', lambda x: '%.10f' % x)        
        df = client.query_df(query)
        
        return df

    @task    
    def process_m_info(df):
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤ —Å—Ç—Ä–æ–∫—É –∑–Ω–∞—á–µ–Ω–∏–π, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—è—Ç—ã–º–∏
        sub1_data = df.loc[(df['sub_type'] == 'sub1')].reset_index(drop=True)
        sub2_data = df.loc[(df['sub_type'] == 'sub2')].reset_index(drop=True)
        sub3_data = df.loc[(df['sub_type'] == 'sub3')].reset_index(drop=True)
    
        correct_partner_id_sub1_data = list(sub1_data['partner_id'].unique())
        correct_partner_id_sub2_data = list(sub2_data['partner_id'].unique())
        correct_partner_id_sub3_data = list(sub3_data['partner_id'].unique())
    
        str_sub1_data = ', '.join(map(str, correct_partner_id_sub1_data))
        str_sub2_data = ', '.join(map(str, correct_partner_id_sub2_data))
        str_sub3_data = ', '.join(map(str, correct_partner_id_sub3_data))
    
        return {
            "sub1": str_sub1_data,
            "sub2": str_sub2_data,
            "sub3": str_sub3_data
        }

    @task # –ó–∞–¥–∞—á–∞ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ 1
    def query_bi_users_maker(data):
        query = f"""
        SELECT
                    partner_id_final AS partner_id,
                    CASE 
                            WHEN project_id = 1 THEN 'Mos' 
                            WHEN project_id = 2 THEN 'Be'
                            WHEN project_id = 4 THEN 'Ba'
                        ELSE 'Vi' 
                    END AS project_id,
                    sub1 AS sub_id,
                    'sub1' AS sub_type,
                    MAX(reg_date) AS max_reg_date,
                    MAX(fd_date) AS max_fd_date
            FROM bi.users
                WHERE partner_id_final IN ({data["sub1"]}) 
                GROUP BY partner_id_final, 
                         project_id, 
                         sub1
        
        UNION ALL
        
        SELECT
                    partner_id_final AS partner_id,
                    CASE 
                            WHEN project_id = 1 THEN 'Mos' 
                            WHEN project_id = 2 THEN 'Be'
                            WHEN project_id = 4 THEN 'Ba'
                        ELSE 'Vi' 
                    END AS project_id,
                    sub2 AS sub_id,
                    'sub2' AS sub_type,
                    MAX(reg_date) AS max_reg_date,
                    MAX(fd_date) AS max_fd_date
            FROM bi.users
                WHERE partner_id_final IN ({data["sub2"]}) 
                GROUP BY partner_id_final, 
                         project_id, 
                         sub2
        
        UNION ALL
        
        SELECT
                    partner_id_final AS partner_id,
                    CASE 
                            WHEN project_id = 1 THEN 'Mos' 
                            WHEN project_id = 2 THEN 'Be'
                            WHEN project_id = 4 THEN 'Ba'
                        ELSE 'Vi' 
                    END AS project_id,
                    sub3 AS sub_id,
                    'sub3' AS sub_type,
                    MAX(reg_date) AS max_reg_date,
                    MAX(fd_date) AS max_fd_date
            FROM bi.users
                WHERE partner_id_final IN ({data["sub3"]}) 
                GROUP BY partner_id_final, 
                         project_id, 
                         sub3
        """
        
        return query

    @task
    def time_str_maker():
        from datetime import datetime, timedelta
        # –ü–æ–ª—É—á–∞–µ–º —Å–µ–≥–æ–¥–Ω—è—à–Ω—é—é –¥–∞—Ç—É
        today = datetime.today()        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ
        days_since_sunday = (today.weekday() + 1) % 7  # weekday() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 0 –¥–ª—è –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞, 6 –¥–ª—è –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å—è        
        # –í—ã—á–∏—Å–ª—è–µ–º –¥–∞—Ç—É –ø—Ä–æ—à–ª–æ–≥–æ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å—è
        last_sunday = today - timedelta(days=days_since_sunday + 7)
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        sunday_str = last_sunday.strftime("%Y-%m-%d")
        
        return sunday_str

    @task # –ó–∞–¥–∞—á–∞ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ 2
    def query_m_partner_maker(data, last_sunday_str):
        query = f"""
        
        SELECT 
                    partner_id ,
                    CASE 
                            WHEN project_id = 1 THEN 'Mos' 
                            WHEN project_id = 2 THEN 'Be'
                            WHEN project_id = 4 THEN 'Ba'
                        ELSE 'Vi' 
                    END AS project_id,
                    sub1 AS sub_id,
                    'sub1' AS sub_type,
                    min(registration_date) AS max_reg_date,
                    toDateTime('1970-01-01 03:00:00') AS max_fd_date
            FROM m_partner.statistics
                WHERE partner_id IN ({data["sub1"]}) 
                GROUP BY partner_id, 
                         project_id, 
                         sub1
                HAVING MIN(registration_date) > '{last_sunday_str}'
                
                UNION ALL
                
        SELECT 
                    partner_id ,
                    CASE 
                            WHEN project_id = 1 THEN 'Mos' 
                            WHEN project_id = 2 THEN 'Be'
                            WHEN project_id = 4 THEN 'Ba'
                        ELSE 'Vi' 
                    END AS project_id,
                    sub2 AS sub_id,
                    'sub2' AS sub_type,
                    min(registration_date) AS max_reg_date,
                    toDateTime('1970-01-01 03:00:00') AS max_fd_date
            FROM m_partner.statistics
                WHERE partner_id IN ({data["sub2"]}) 
                GROUP BY partner_id, 
                         project_id, 
                         sub2
                HAVING MIN(registration_date) > '{last_sunday_str}'
                
                UNION ALL
                
        SELECT 
                    partner_id ,
                    CASE 
                            WHEN project_id = 1 THEN 'Mos' 
                            WHEN project_id = 2 THEN 'Be'
                            WHEN project_id = 4 THEN 'Ba'
                        ELSE 'Vi' 
                    END AS project_id,
                    sub3 AS sub_id,
                    'sub3' AS sub_type,
                    min(registration_date) AS max_reg_date,
                    toDateTime('1970-01-01 03:00:00') AS max_fd_date
            FROM m_partner.statistics
                WHERE partner_id IN ({data["sub3"]}) 
                GROUP BY partner_id, 
                         project_id, 
                         sub3
                HAVING MIN(registration_date) > '{last_sunday_str}'
        """
        
        return query

    @task ### –¥–ª—è –ø—Ä–∏—á–µ—Å—ã–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    def valid_data_maker(data_1, data_2):
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–ª–æ–Ω–∫—É –≤ —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã
        data_1[['max_reg_date', 
                'max_fd_date']] = data_1[['max_reg_date', 'max_fd_date']].apply(pd.to_datetime)
        
        data_2[['max_reg_date', 
                'max_fd_date']] = data_2[['max_reg_date', 'max_fd_date']].apply(pd.to_datetime)
        
        data_1 = data_1.astype({
                                'partner_id': 'int64',
                                'project_id': 'str',
                                'sub_id': 'str',
                                'sub_type': 'str'
                            })
        data_2 = data_2.astype({
                                'partner_id': 'int64',
                                'project_id': 'str',
                                'sub_id': 'str',
                                'sub_type': 'str'
                            })
        final_sub_list_data = pd.concat([data_1, data_1], ignore_index=True)
        
        return final_sub_list_data

#######################################################################################
################  Step 2 ####################################################
###################################################################################### 
    @task # Google
    def simple_excel_google_sheets(api_google_sn, sheet_url, dataframes, delegated_email, users):
        import gspread
        import pandas as pd
        from google.oauth2.service_account import Credentials
        import os    
        print("Current working directory:", os.getcwd())
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –¥–æ—Å—Ç—É–ø –∫ Google Sheets —á–µ—Ä–µ–∑ —Å–µ—Ä–≤–∏—Å–Ω—ã–π –∞–∫–∫–∞—É–Ω—Ç —Å –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        scopes = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        credentials = Credentials.from_service_account_file(api_google_sn, scopes=scopes)
        credentials = credentials.with_subject(delegated_email)
        client = gspread.authorize(credentials) 
        
        try:
            # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª –ø–æ —Å—Å—ã–ª–∫–µ
            spreadsheet = client.open_by_url(sheet_url)
            print(f'–§–∞–π–ª –ø–æ —Å—Å—ã–ª–∫–µ "{sheet_url}" –Ω–∞–π–¥–µ–Ω. –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ.')
        except Exception as e:
            print(f'–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª –ø–æ —Å—Å—ã–ª–∫–µ: {e}')
            
            return
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π DataFrame –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –ª–∏—Å—Ç
        for name, df in dataframes.items():
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—ã –≤ —Å—Ç—Ä–æ–∫–∏
            for col in df.columns:
                if pd.api.types.is_datetime64_any_dtype(df[col]):
                    df[col] = df[col].astype(str)
    
            try:
                worksheet = spreadsheet.worksheet(name)
                worksheet.clear()
                print(f'–õ–∏—Å—Ç "{name}" –Ω–∞–π–¥–µ–Ω. –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ.')
            except gspread.WorksheetNotFound:
                worksheet = spreadsheet.add_worksheet(title=name, rows=df.shape[0] + 1, cols=df.shape[1])
                print(f'–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –ª–∏—Å—Ç: {name}')    
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –∑–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö –æ–¥–Ω–æ–π –ø–∞—á–∫–æ–π
            data = [df.columns.tolist()] + df.astype(str).values.tolist()
            worksheet.update("A1", data)
            print(f'–õ–∏—Å—Ç "{name}" –æ–±–Ω–æ–≤–ª—ë–Ω. –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ (–≤–∫–ª—é—á–∞—è –∑–∞–≥–æ–ª–æ–≤–∫–∏): {len(data)}')
    
        # –®–∞—Ä–∏–º –¥–æ—Å—Ç—É–ø
        if users:
            for user in users:
                #spreadsheet.share(user, perm_type='user', role='writer')
                print(f'–î–æ—Å—Ç—É–ø –æ—Ç–∫—Ä—ã—Ç –¥–ª—è {user}')
        else:
            print('–°–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø—É—Å—Ç, –¥–æ—Å—Ç—É–ø –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω.')
    
        print(f'–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω.')

     ###   
    @task # —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–±–∏–≤–∫–∞ –≤ –¢–µ–ª–µ–≥—Ä–∞–º–º –±–æ—Ç–∞
    def send_message_tg(bot_conn, message ):
        #message = "üîäTest message! ‚úÖ"  # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
        
        telegram_conn = BaseHook.get_connection(bot_conn)  # –ò–º—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        bot_token = telegram_conn.password  # –¢–æ–∫–µ–Ω –±–æ—Ç–∞
        chat_id = telegram_conn.host  # chat_id, –∫–æ—Ç–æ—Ä—ã–π —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ host
        print(f"Using bot token: {bot_token}")
        print(f"Using chat id: {chat_id}")
        
        url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
        data = {
            "chat_id": chat_id,
            "text": message,
            "parse_mode": "HTML"
        }
        response = requests.post(url, data=data)
        print(f'Sending message: {message}')
        print(f'Response: {response.status_code}, {response.text}')
        if response.status_code != 200:
            print(f"Failed to send message: {response.text}")
            
            
#######################################################################################
################  Step 3 ####################################################
###################################################################################### 
    # –®–∞–≥–∏: –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏—Ö –∏ —Å—Ç—Ä–æ–∏–º –∑–∞–ø—Ä–æ—Å
    # –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å
    query_m_info = f"""
    SELECT site, partner_id, sub_type
    FROM reports.m_info
    WHERE business_unit ILIKE '%acquis%' AND sub_type != ''
    """
    # –∏–Ω—Ñ–∞ –¥–ª—è –≥—É–≥–ª–∞
    api_google_sn = r'/opt/airflow/dags/advivambcash-591ssda91a.json'
    delegated_email = 'd.username_example@ars.cloud'
    medbuy_ratings_file_name = 'https://docs.google.com/spreadsheets/d/1a665fIJUj2kytlf2YmfxrBjgKlLp'
    users = ["d.username_example@ars.cloud"]
    
    bot = send_message_tg(bot_conn = "m_alerts_bot", message = "üîä<b>–§–∞–π–ª:<u>–†–∞—Å—Ö–æ–¥—ã –Ω–∞ –ø–∞—Ä—Ç–Ω–µ—Ä–æ–≤</u></b>\n\nüë®‚Äçüíª–ù–∞—á–∏–Ω–∞—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª–∏—Å—Ç–∞ –±–∞–∑—ã")

    
    # –®–∞–≥–∏: –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏—Ö –∏ —Å—Ç—Ä–æ–∏–º –∑–∞–ø—Ä–æ—Å
    m_info__ = df_from_val(query = query_m_info, base = "reports")
    partner_id_strings = process_m_info(m_info__)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
    query_bi_users = query_bi_users_maker(partner_id_strings)
    # –ü–æ–¥–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —é–∑–µ—Ä—Å
    val_partner_data = df_from_val(query = query_bi_users, base = "bi")
    # –≤—ã—á–∏—Å–ª—è–µ–º –¥–∞—Ç—É
    last_sunday_str = time_str_maker()
    query_m_partner = query_m_partner_maker(data = partner_id_strings, last_sunday_str = last_sunday_str)
    m_partner_data = df_from_m_partner( query = query_m_partner, base = "m_partner" )

####### FINAL
    final__data = valid_data_maker(data_1 = val_partner_data, data_2 = m_partner_data)
    dataframes = {'base':final__data}

    data_to_google = simple_excel_google_sheets(api_google_sn, medbuy_ratings_file_name, dataframes, delegated_email, users)

    bot = send_message_tg(bot_conn = "m_alerts_bot", message = "üîä<b>–§–∞–π–ª:<u>–†–∞—Å—Ö–æ–¥—ã –Ω–∞ –ø–∞—Ä—Ç–Ω–µ—Ä–æ–≤</u></b>\n\nüë®‚Äçüíª–î–∞–Ω–Ω—ã–µ –Ω–∞ –ª–∏—Å—Ç–µ base –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã! ‚úÖ")

### –°–æ–±–∏—Ä–∞–µ–º –¥–∞–≥:
    (
        m_info__ >> 
        partner_id_strings >> 
        query_bi_users >> 
        val_partner_data >> 
        last_sunday_str >> 
        query_m_partner >> 
        m_partner_data >> 
        final__data >>
        data_to_google >>
        bot
    )

m_pid_sub_base_list_updater()